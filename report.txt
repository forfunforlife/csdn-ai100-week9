训练数据准备
从convert_fcn_dataset.py脚本出发,补全缺失代码。
在本地执行,生成的两个文件fcn_train.record,fcn_val.record,分别在400MB左右。

预训练模型
预训练模型使用tensorflow，modelzoo中的VGG16模型

模型
在参考代码：https://gitee.com/ai100/quiz-w9-code.git train.py基础上添加8X的FCN实现并进行训练。

train.py中补全8x代码的上采样过程及其结果的融合, 重命名文件train_8x.py

#取下采样８倍的特征,用１x１的卷积核反卷积运算，生成２１张特征图，每张图对应一个分类
pool3_feature = end_points['vgg_16/pool3']
with tf.variable_scope('vgg_16/fc8'):
    aux_logits_8s = slim.conv2d(pool3_feature, number_of_classes, [1, 1],
                                 activation_fn=None,
                                 weights_initializer=tf.zeros_initializer,
                                 scope='conv_pool3')

# Perform the second 2x upsampling
upsample_filter_np_x2_2 = bilinear_upsample_weights(2,  # upsample_factor,
                                                  number_of_classes)

upsample_filter_tensor_x2_2 = tf.Variable(upsample_filter_np_x2_2, name='vgg_16/fc8/t_conv_x2_2')

upsampled_logits_x2 = tf.nn.conv2d_transpose(upsampled_logits, upsample_filter_tensor_x2_2,
                                          output_shape=tf.shape(aux_logits_8s),
                                          strides=[1, 2, 2, 1],
                                          padding='SAME')

upsampled_logits_x2 = upsampled_logits_x2 + aux_logits_8s

# upsample_filter_np_x16 = bilinear_upsample_weights(upsample_factor,
#                                                    number_of_classes)

# upsample_filter_tensor_x16 = tf.Variable(upsample_filter_np_x16, name='vgg_16/fc8/t_conv_x16')
# upsampled_logits = tf.nn.conv2d_transpose(upsampled_logits, upsample_filter_tensor_x16,
#                                           output_shape=upsampled_logits_shape,
#                                           strides=[1, upsample_factor, upsample_factor, 1],
#                                           padding='SAME')
upsample_factor_8s = 8
upsample_filter_np_x8 = bilinear_upsample_weights(upsample_factor_8s,
                                                   number_of_classes)

upsample_filter_tensor_x8 = tf.Variable(upsample_filter_np_x8, name='vgg_16/fc8/t_conv_x8')
upsampled_logits_x2 = tf.nn.conv2d_transpose(upsampled_logits_x2, upsample_filter_tensor_x8,
                                          output_shape=upsampled_logits_shape,
                                          strides=[1, upsample_factor_8s, upsample_factor_8s, 1],
                                          padding='SAME')


lbl_onehot = tf.one_hot(annotation_tensor, number_of_classes)
cross_entropies = tf.nn.softmax_cross_entropy_with_logits(logits=upsampled_logits_x2,
                                                          labels=lbl_onehot)

cross_entropy_loss = tf.reduce_mean(tf.reduce_sum(cross_entropies, axis=-1))


# Tensor to get the final prediction for each pixel -- pay
# attention that we don't need softmax in this case because
# we only need the final decision. If we also need the respective
# probabilities we will have to apply softmax.
pred = tf.argmax(upsampled_logits_x2, axis=3)

probabilities = tf.nn.softmax(upsampled_logits_x2)


